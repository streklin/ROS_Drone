{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RoverImageIterator:\n",
    "    \n",
    "    def __init__(self, num_rover_images, img_dir, msk_dir):\n",
    "        self.num_rover_images = num_rover_images\n",
    "        self.img_dir = img_dir\n",
    "        self.msk_dir = msk_dir\n",
    "        \n",
    "        self.iterator = 0\n",
    "        self.img_pairs = []\n",
    "        \n",
    "    \n",
    "    # creates a list of file name / mask name pairs and shuffles them.\n",
    "    # these will be used to create the batches during training.\n",
    "    def setup_rover_iterator(self):\n",
    "        \n",
    "        # reset the iterator\n",
    "        self.iterator = 0\n",
    "        self.img_pairs = []\n",
    "        \n",
    "        for i in range(self.num_rover_images):\n",
    "            img_std_file = self.img_dir + \"img_\" + str(i) + \".jpg\"\n",
    "            img_flp_file = self.img_dir + \"img_flipped_\" + str(i) + \".jpg\"\n",
    "            img_msk_file = self.msk_dir + \"img_mask_\" + str(i) + \".jpg\"\n",
    "            img_flp_msk_file = self.msk_dir + \"img_flipped_mask_\" + str(i) + \".jpg\"\n",
    "            \n",
    "            self.img_pairs.append( (img_std_file, img_msk_file) )\n",
    "            self.img_pairs.append( (img_flp_file, img_flp_msk_file) )\n",
    "        \n",
    "        np.random.shuffle(self.img_pairs)\n",
    "        \n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        batch_files = []\n",
    "\n",
    "        if self.iterator + batch_size < len(self.img_pairs):\n",
    "            batch_files = self.img_pairs[self.iterator:self.iterator+batch_size]\n",
    "            self.iterator += batch_size\n",
    "        else:\n",
    "            diff = (self.iterator + batch_size) - len(self.img_pairs)\n",
    "            \n",
    "            batch_files_1 = self.img_pairs[self.iterator:len(self.img_pairs)]\n",
    "            batch_files_2 = self.img_pairs[0:diff]\n",
    "            \n",
    "            batch_files = batch_files_1 + batch_files_2\n",
    "        \n",
    "        \n",
    "        images = []\n",
    "        masks = []\n",
    "        \n",
    "        for img_file, msk_file in batch_files:\n",
    "            img = scipy.ndimage.imread(img_file) / 255 # normalize inputs\n",
    "            msk = scipy.ndimage.imread(msk_file)\n",
    "            \n",
    "            images.append(img)\n",
    "            masks.append(msk)\n",
    "    \n",
    "        return images, masks\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return init_bias_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cov2d(x, W):\n",
    "    # x shape [batch_size, height, width, channels]\n",
    "    # W shape [ filter H, filter W, Ch In, Ch Out ]\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pooling_2by2(x):\n",
    "    # x shape [batch, height, width, channels]\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutional_layer(x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    \n",
    "    return tf.nn.relu(cov2d(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create convolutional layer followed by max pooling.  \n",
    "# Kernel size is assumed to be symetric (so kernel size = 3 creates a 3x3 kernel)\n",
    "# Input Tensor: [None, Image_height, Image_width, num_channels]\n",
    "# Output Tensor: [None, 0.5 * Image_Height, 0.5 * Image_Width, num_filters]\n",
    "def encoder_layer(x, kernel_size, num_channels, num_filters):\n",
    "    layer = convolutional_layer(x, [kernel_size, kernel_size, num_channels, num_filters])\n",
    "    layer_max_pool = max_pooling_2by2(layer)\n",
    "    \n",
    "    return layer_max_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is inspired by standard FCN models, but with a bit of a simplification.  As I am not interested,\n",
    "nor have the correct training data for, pixel level image segmentation, I've decided to try an approach\n",
    "that basically drops the bilinear upsampling / decoder layers.  Here I am very much interested in a heat\n",
    "map of probable locations in the image where I might find my rover, not the rovers boundary.  The approach\n",
    "then is to keep the encoder layers, but simply have a standard convolutional layer at the end that just outputs\n",
    "the current heat map without upsampling. So I'll be taking in 640x480 images and outputing 160X120 heatmaps.\n",
    "\n",
    "<br/>\n",
    "\n",
    "As I am only interested in the positional state of a single object, the heat maps can be black and white versions\n",
    "of the original masks, scaled down to 160x120.  This should greatly reduce the number of parameters that need be \n",
    "learned and make it easier for the network to perform the task at hand.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "<br/>input layer - 640x480x3\n",
    "<br/>conv / max pool - 320x240x32 \n",
    "<br/>conv / max pool - 160x120x64\n",
    "<br/>1x1 conv - 160x120x128\n",
    "<br/>1x1 conv - 160x120x64\n",
    "<br/>1x1 conv - 160x120x32\n",
    "<br/>conv layer (no pooling) 160x120x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fcn_heatmap_model(inputs):\n",
    "    encoder_layer1 = encoder_layer(x=inputs, kernel_size=3, num_channels=3, num_filters=32)\n",
    "    \n",
    "    encoder_layer2 = encoder_layer(x=encoder_layer1, kernel_size=3, num_channels=32, num_filters=64)\n",
    "    \n",
    "    one_by_one_1 = convolutional_layer(x=encoder_layer2, shape=[1, 1, 64, 128])\n",
    "    one_by_one_2 = convolutional_layer(x=one_by_one_1, shape=[1, 1, 128, 64])\n",
    "    one_by_one_3 = convolutional_layer(x=one_by_one_2, shape=[1, 1, 64, 32])\n",
    "    \n",
    "    return convolutional_layer(x=one_by_one_3, shape=[3, 3, 32, 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "learning_rate = 0.002\n",
    "num_iterations = 1000\n",
    "batch_size = 2 # not a lot of memory on my laptop and not much of a gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, 480, 640, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 120, 160, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fcn_heatmap_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(model - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_history = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        x_batch, y_batch = rover_image_iterator.next_batch(batch_size=batch_size)\n",
    "        \n",
    "        sess.run(train, feed_dict={x: x_batch, y:y_batch})\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            error = loss.eval(feed_dict={x: x_batch, y:y_batch})\n",
    "            print(\"Iteration: \", iteration, \"\\t\", error)\n",
    "            error_history.append(error)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
